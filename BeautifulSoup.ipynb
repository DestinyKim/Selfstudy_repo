{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <a href=\"https://www.google.com\">구글</a>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "        <a href=\"https://www.naver.com/\">네이버</a>\n",
    "        <a href=\"https://www.daum.com/\">다음</a>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title> test site </title>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div>\n",
       "<a href=\"https://www.google.com\">구글</a>\n",
       "<p align=\"left\" class=\"class1\">test3</p>\n",
       "<p class=\"class1\">test2</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div1 = soup.find(\"div\")\n",
    "div1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <a href=\"https://www.google.com\">구글</a>,\n",
       " '\\n',\n",
       " <p align=\"left\" class=\"class1\">test3</p>,\n",
       " '\\n',\n",
       " <p class=\"class1\">test2</p>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(div1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-3 주어진 코드에서 children 속성을 이용해서 span 태그 요소를 가져와 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"class3\">span tag text</span>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div2 = soup.find_all(\"div\")[1].children\n",
    "list(div2)[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-2 p 태그의 text를 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"left\" class=\"class1\">test3</p>,\n",
       " <p class=\"class1\">test2</p>,\n",
       " <p id=\"p1\">오늘의 주가지수 1500</p>,\n",
       " <p class=\"class4\">test3</p>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_all = soup.find('body').find_all('p')\n",
    "p_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test3\n",
      "test2\n",
      "오늘의 주가지수 1500\n",
      "test3\n"
     ]
    }
   ],
   "source": [
    "for one in p_all:\n",
    "    print(one.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(추가) a태그의 url 및 text가져오기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글 https://www.google.com\n",
      "네이버 https://www.naver.com/\n",
      "다음 https://www.daum.com/\n"
     ]
    }
   ],
   "source": [
    "list_a = soup.find_all(\"a\")\n",
    "for one in list_a:\n",
    "    print(one.text,one.get(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가져온 url 및 text를 csv파일로 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글 https://www.google.com\n",
      "네이버 https://www.naver.com/\n",
      "다음 https://www.daum.com/\n",
      "['구글', '네이버', '다음']\n",
      "['https://www.google.com', 'https://www.naver.com/', 'https://www.daum.com/']\n"
     ]
    }
   ],
   "source": [
    "com = []\n",
    "urls = []\n",
    "list_a = soup.findAll(\"a\")\n",
    "for one in list_a:\n",
    "    print(one.text, one.get(\"href\"))\n",
    "    com.append(one.text)\n",
    "    urls.append(one.get('href'))\n",
    "print(com)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  csv파일 만들기 - pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas의 기본 자료형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Series\n",
    "* DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>웹사이트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구글</td>\n",
       "      <td>https://www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네이버</td>\n",
       "      <td>https://www.naver.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>다음</td>\n",
       "      <td>https://www.daum.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   회사명                    웹사이트\n",
       "0   구글  https://www.google.com\n",
       "1  네이버  https://www.naver.com/\n",
       "2   다음   https://www.daum.com/"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = {'회사명':com, '웹사이트':urls}\n",
    "dat = pd.DataFrame(dat)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jongho\\Documents\\Practice\n",
      "['.ipynb_checkpoints', '20210616 BeautifulSoup.ipynb', 'Untitled.ipynb', '회사명과 웹사이트.csv']\n"
     ]
    }
   ],
   "source": [
    "dat.to_csv(\"회사명과 웹사이트.csv\", index=False)\n",
    "\n",
    "# 확인\n",
    "import os\n",
    "print(os.getcwd())  # 현재 위치\n",
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel 파일로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jongho\\Documents\\Practice\n",
      "['.ipynb_checkpoints', '20210616 BeautifulSoup.ipynb', 'Untitled.ipynb', '회사명과 웹사이트.csv', '회사명과 웹사이트.xlsx']\n"
     ]
    }
   ],
   "source": [
    "dat.to_excel(\"회사명과 웹사이트.xlsx\", index=False)\n",
    "\n",
    "# 확인\n",
    "import os\n",
    "print(os.getcwd()) # 현재 위치\n",
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 주식 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "page\n",
    "soup = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>국내증시 : 네이버 금융</title>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "금일 증시 코스피 지수는 3,276.53 ,코스닥 지수는 999.01 ,코스피200 지수는 436.59 입니다\n"
     ]
    }
   ],
   "source": [
    "kospi = soup.find_all(\"span\",id=\"KOSPI_now\")[0].text\n",
    "kosdaq = soup.find_all(\"span\",id=\"KOSDAQ_now\")[0].text\n",
    "kpi200 = soup.find_all(\"span\",id=\"KPI200_now\")[0].text\n",
    "print(\"금일 증시 코스피 지수는\",kospi,\",코스닥 지수는\",kosdaq,\",코스피200 지수는\",kpi200,\"입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코스피 : 3,276.53 / 코스닥 : 999.01 / 코스피200 : 436.59\n"
     ]
    }
   ],
   "source": [
    "kospi = soup.find(\"span\",id=\"KOSPI_now\").text\n",
    "kosdaq = soup.find(\"span\",id=\"KOSDAQ_now\").text\n",
    "kpi200 = soup.find(\"span\",id=\"KPI200_now\").text\n",
    "print(\"코스피 :\",kospi,\"/ 코스닥 :\",kosdaq,\"/ 코스피200 :\",kpi200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인기 검색 종목 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <a href=\"/item/main.nhn?code=035420\" onclick=\"clickcr(this,'boa.list','035420','1',event)\">NAVER</a>\n",
      "1 <a href=\"/item/main.nhn?code=005930\" onclick=\"clickcr(this,'boa.list','005930','2',event)\">삼성전자</a>\n",
      "2 <a href=\"/item/main.nhn?code=004410\" onclick=\"clickcr(this,'boa.list','004410','3',event)\">서울식품</a>\n",
      "3 <a href=\"/item/main.nhn?code=035720\" onclick=\"clickcr(this,'boa.list','035720','4',event)\">카카오</a>\n",
      "4 <a href=\"/item/main.nhn?code=034020\" onclick=\"clickcr(this,'boa.list','034020','5',event)\">두산중공업</a>\n",
      "5 <a href=\"/item/main.nhn?code=102280\" onclick=\"clickcr(this,'boa.list','102280','6',event)\">쌍방울</a>\n",
      "6 <a href=\"/item/main.nhn?code=011200\" onclick=\"clickcr(this,'boa.list','011200','7',event)\">HMM</a>\n",
      "7 <a href=\"/item/main.nhn?code=006340\" onclick=\"clickcr(this,'boa.list','006340','8',event)\">대원전선</a>\n",
      "8 <a href=\"/item/main.nhn?code=001440\" onclick=\"clickcr(this,'boa.list','001440','9',event)\">대한전선</a>\n",
      "9 <a href=\"/item/main.nhn?code=130660\" onclick=\"clickcr(this,'boa.list','130660','10',event)\">한전산업</a>\n"
     ]
    }
   ],
   "source": [
    "pop = soup.find(\"ul\",id=\"popularItemList\").find_all(\"a\")\n",
    "pops = list(pop)\n",
    "for idx, one in enumerate(pops):\n",
    "    print(idx, one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 해당 정보가 있는 부분을 가져온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li><em>1.</em><a href=\"/item/main.nhn?code=035420\" onclick=\"clickcr(this,'boa.list','035420','1',event)\">NAVER</a><span class=\"up\">393,500</span><em class=\"bu_p bu_pup\"><span class=\"blind\">상승</span></em></li>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_stock = soup.find(\"ul\",id=\"popularItemList\")\n",
    "\n",
    "stock_all = search_stock.find_all(\"li\")\n",
    "stock_all[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAVER\n",
      "393,500\n"
     ]
    }
   ],
   "source": [
    "print(stock_all[0].find(\"a\").text)\n",
    "print(stock_all[0].find(\"span\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAVER', '삼성전자', '서울식품', '카카오', '두산중공업', '쌍방울', 'HMM', '대원전선', '대한전선', '한전산업'] ['393,500', '81,500', '460', '143,500', '24,500', '1,275', '45,600', '3,480', '3,290', '10,900']\n",
      "['393,500', '81,500', '460', '143,500', '24,500', '1,275', '45,600', '3,480', '3,290', '10,900']\n"
     ]
    }
   ],
   "source": [
    "com_all = []\n",
    "price_all = []\n",
    "for one in stock_all:\n",
    "    com_one = one.find(\"a\").text \n",
    "    price_one = one.find(\"span\").text \n",
    "    com_all.append(com_one)\n",
    "    price_all.append(price_one)\n",
    "print(com_all,price_all)\n",
    "print(price_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-3 (추가) 인기 검색 종목 +(상승), -(하락) 포함시키기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li><em>1.</em><a href=\"/item/main.nhn?code=035420\" onclick=\"clickcr(this,'boa.list','035420','1',event)\">NAVER</a><span class=\"up\">391,500</span><em class=\"bu_p bu_pup\"><span class=\"blind\">상승</span></em></li> \n",
      "\n",
      "NAVER\n",
      "391,500\n",
      "['NAVER', '삼성전자', '대원전선', '쌍방울', '카카오', '두산중공업', 'HMM', '서울식품', '대한전선', '한전산업']\n",
      "['391,500', '81,600', '3,595', '1,295', '143,500', '24,550', '45,250', '454', '3,285', '10,950']\n",
      "['상승', '상승', '상승', '하락', '하락', '상승', '상승', '상승', '상승', '상승']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://finance.naver.com/sise/'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "search_stock = soup.find(\"ul\", id=\"popularItemList\")\n",
    "stock_all = search_stock.find_all(\"li\")\n",
    "# 하나씩 하기\n",
    "print(stock_all[0], \"\\n\")\n",
    "print(stock_all[0].find(\"a\").text)\n",
    "print(stock_all[0].find(\"span\").text)\n",
    "com_all = []\n",
    "price_all = []\n",
    "updown_all = []\n",
    "for one in stock_all :\n",
    "    com_one = one.find(\"a\").text\n",
    "    price_one = one.find(\"span\").text\n",
    "    updown_one = one.find(\"span\", class_=\"blind\").text\n",
    "    com_all.append(com_one)\n",
    "    price_all.append(price_one)\n",
    "    updown_all.append(updown_one)\n",
    "print(com_all)\n",
    "print(price_all)\n",
    "print(updown_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-3 (추가) 인기 검색 종목 코드 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company    price 상승/하락    상품코드\n",
      "0    삼성전자   81,600    상승  005930\n",
      "1   NAVER  391,500    상승  035420\n",
      "2   두산중공업   24,600    상승  034020\n",
      "3    대원전선    3,630    상승  006340\n",
      "4     카카오  143,000    하락  035720\n",
      "5     쌍방울    1,290    하락  102280\n",
      "6     HMM   45,450    상승  011200\n",
      "7     가비아   19,100   상한가  079940\n",
      "8    대한전선    3,290    상승  001440\n",
      "9    서울식품      447    상승  004410\n"
     ]
    }
   ],
   "source": [
    "## naver finance 인기 종목 by. 양효진\n",
    "\n",
    "popularList = soup.find(\"ul\", id=\"popularItemList\").find_all(\"li\")\n",
    "com_all =[]\n",
    "price_all=[]\n",
    "updown_all=[]\n",
    "stockcode_all=[]\n",
    "\n",
    "for i in popularList:\n",
    "  com_all.append(i.find(\"a\").text)\n",
    "  price_all.append(i.find(\"span\").text)\n",
    "  updown_all.append(i.find(\"span\", class_=\"blind\").text)  \n",
    "  stockcode_all.append(i.find('a').attrs['href'][-6:])\n",
    "data={\"company\": com_all, \"price\":price_all, \"상승/하락\":updown_all,\"상품코드\":stockcode_all}\n",
    "stock=pd.DataFrame(data)\n",
    "print(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>com</th>\n",
       "      <th>up_down</th>\n",
       "      <th>price</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>삼성전자</td>\n",
       "      <td>상승</td>\n",
       "      <td>81,600</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>NAVER</td>\n",
       "      <td>상승</td>\n",
       "      <td>391,500</td>\n",
       "      <td>035420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>두산중공업</td>\n",
       "      <td>상승</td>\n",
       "      <td>24,600</td>\n",
       "      <td>034020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>대원전선</td>\n",
       "      <td>상승</td>\n",
       "      <td>3,630</td>\n",
       "      <td>006340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>카카오</td>\n",
       "      <td>하락</td>\n",
       "      <td>143,000</td>\n",
       "      <td>035720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>쌍방울</td>\n",
       "      <td>하락</td>\n",
       "      <td>1,290</td>\n",
       "      <td>102280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>HMM</td>\n",
       "      <td>상승</td>\n",
       "      <td>45,450</td>\n",
       "      <td>011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>가비아</td>\n",
       "      <td>상한가</td>\n",
       "      <td>19,100</td>\n",
       "      <td>079940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>대한전선</td>\n",
       "      <td>상승</td>\n",
       "      <td>3,290</td>\n",
       "      <td>001440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>서울식품</td>\n",
       "      <td>상승</td>\n",
       "      <td>447</td>\n",
       "      <td>004410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rank    com up_down    price    code\n",
       "0   1.   삼성전자      상승   81,600  005930\n",
       "1   2.  NAVER      상승  391,500  035420\n",
       "2   3.  두산중공업      상승   24,600  034020\n",
       "3   4.   대원전선      상승    3,630  006340\n",
       "4   5.    카카오      하락  143,000  035720\n",
       "5   6.    쌍방울      하락    1,290  102280\n",
       "6   7.    HMM      상승   45,450  011200\n",
       "7   8.    가비아     상한가   19,100  079940\n",
       "8   9.   대한전선      상승    3,290  001440\n",
       "9  10.   서울식품      상승      447  004410"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## naver finance 인기 종목 by. 이응진\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "page\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "all_pop = soup.find(\"ul\", class_=\"lst_pop\").find_all(\"li\")\n",
    "all_data = []\n",
    "for li in all_pop:\n",
    "    dic = {}\n",
    "    dic[\"rank\"] = li.find(\"em\").text\n",
    "    dic[\"com\"] = li.find(\"a\").text\n",
    "    dic[\"up_down\"] = li.find('span', class_='blind').text\n",
    "    dic[\"price\"] = li.find('span').text\n",
    "    dic[\"code\"] = li.find('a').get(\"onclick\").split(',')[2].strip(\"''\")\n",
    "    all_data.append(dic)\n",
    "dat = pd.DataFrame(all_data)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자의 코드 :  005930\n",
      "두산중공업의 코드 :  034020\n",
      "카카오의 코드 :  035720\n",
      "NAVER의 코드 :  035420\n",
      "대원전선의 코드 :  006340\n",
      "HMM의 코드 :  011200\n",
      "서울식품의 코드 :  004410\n",
      "쌍방울의 코드 :  102280\n",
      "대한전선의 코드 :  001440\n",
      "가비아의 코드 :  079940\n"
     ]
    }
   ],
   "source": [
    "## naver finance 인기 종목 by. 이예준\n",
    "\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "rank_1 = soup.find('div', class_='rgt')\n",
    "rank_1 = soup.findAll('ul', id='popularItemList')\n",
    "list_rank = rank_1[0].findAll('li')\n",
    "for i in list_rank:\n",
    "    code = i.find('a')\n",
    "    company = code.text\n",
    "    code = code.get('href')\n",
    "    print(company+'의 코드 : ', code[-6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['삼성전자', '쌍방울', '카카오', '대원전선', '두산중공업', 'HMM', 'NAVER', '한전산업', '서울식품', '대한전선']\n",
      "['81,700', '1,210', '143,500', '3,580', '24,450', '45,100', '390,500', '11,000', '438', '3,270']\n",
      "['상승', '하락', '하락', '상승', '상승', '상승', '상승', '상승', '상승', '상승']\n",
      "[\"'005930'\", \"'102280'\", \"'035720'\", \"'006340'\", \"'034020'\", \"'011200'\", \"'035420'\", \"'130660'\", \"'004410'\", \"'001440'\"]\n"
     ]
    }
   ],
   "source": [
    "search_stock=soup.find('ul',id='popularItemList')\n",
    "stock_all=search_stock.find_all('li')\n",
    "com_all=[]\n",
    "price_all=[]\n",
    "rank_all=[]\n",
    "code_all=[]\n",
    "for one in stock_all:\n",
    "    com_one=one.find('a').text\n",
    "    price_one=one.find('span').text\n",
    "    rank_one=one.find('span',class_='blind').text\n",
    "    code_one=one.find('a').get(\"onclick\").split(',')[2]\n",
    "    com_all.append(com_one)\n",
    "    price_all.append(price_one)\n",
    "    rank_all.append(rank_one)\n",
    "    code_all.append(code_one)\n",
    "print(com_all)\n",
    "print(price_all)\n",
    "print(rank_all)\n",
    "print(code_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-3 (추가) 인기 검색 종목 코드 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://finance.naver.com/sise/'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "pop = soup.find(\"ul\",id=\"popularItemList\")\n",
    "pop_list = pop.findAll(\"li\")\n",
    "company_all = []\n",
    "updown_all = []\n",
    "price_all = []\n",
    "code_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>등락</th>\n",
       "      <th>가격</th>\n",
       "      <th>코드번호</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [회사명, 등락, 가격, 코드번호]\n",
       "Index: []"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for one in pop_list:\n",
    "    dic = {}\n",
    "    dic[\"rank\"] = li.find(\"em\").text\n",
    "    dic[\"company_all\"] = one.find(\"a\").text\n",
    "    dic[\"updown_all\"] = one.find_all(\"span\")[1].text\n",
    "    dic[\"price_all\"] = one.find(\"span\").text\n",
    "    dic[\"code_all\"] = one.find(\"a\").get(\"href\").split(\"=\")[-1]\n",
    "    \n",
    "#     company_all = one.find(\"a\").text #회샤명\n",
    "#     price_all =  one.find(\"span\").text #가격\n",
    "#     updown_all = one.find_all(\"span\")[1].text # 상한가&하한가\n",
    "#     code_all= one.find(\"a\").get(\"href\").split(\"=\")[-1] #코드\n",
    "    \n",
    "    all_data.append(dic)\n",
    "    \n",
    "\n",
    "dat = {'회사명':company_all, '등락':updown_all, '가격':price_all, '코드번호':code_all}\n",
    "dat = pd.DataFrame(dat)\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제(자율과제)\n",
    "   * Top 종목에 있는 상한가정보를 가져와서 xlsx파일로 정리하기\n",
    "   * 제출 : 구글 드라이브"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
